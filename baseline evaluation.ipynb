{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcae74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "import re\n",
    "from fractions import Fraction\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8c1be9",
   "metadata": {},
   "source": [
    "# Create the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "616ef70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('home_depot_data/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv('home_depot_data/test.csv', encoding=\"ISO-8859-1\")\n",
    "df_attr = pd.read_csv('home_depot_data/attributes.csv')\n",
    "df_pro_desc = pd.read_csv('home_depot_data/product_descriptions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15600763",
   "metadata": {},
   "source": [
    "# Add stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56870a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "def str_stemmer(s):\n",
    "\treturn \" \".join([stemmer.stem(word) for word in s.lower().split()])\n",
    "\n",
    "def str_common_word(str1, str2):\n",
    "\treturn sum(int(str2.find(word)>=0) for word in str1.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f13f5",
   "metadata": {},
   "source": [
    "# Dataframe processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38fb4b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_base = df_train.drop(['search_term','product_title'],axis=1)\n",
    "df_train['search_term'] = df_train['search_term'].map(lambda x:str_stemmer(x))\n",
    "df_train['product_title'] = df_train['product_title'].map(lambda x:str_stemmer(x))\n",
    "df_train['len_of_query'] = df_train['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_train['product_info'] = df_train['search_term']+\"\\t\"+df_train['product_title']\n",
    "df_train['word_in_title'] = df_train['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "df_complete=df_train\n",
    "df_train = df_train.drop(['search_term','product_title', 'product_info'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8030299",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_train, test_size=0.2, random_state=42)\n",
    "base_train, base_test = train_test_split(df_train_base, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ffe48",
   "metadata": {},
   "source": [
    "# Define test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "908d4b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_test = test['id']\n",
    "y_train = train['relevance'].values\n",
    "X_train = train.drop(['id','relevance'],axis=1).values\n",
    "X_test = test.drop(['id','relevance'],axis=1).values\n",
    "y_test = test['relevance'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60f963f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=42)\n",
    "clf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dcb0c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_base_test = base_test['id']\n",
    "y_base_train = base_train['relevance'].values\n",
    "X_base_train = base_train.drop(['id','relevance'],axis=1).values\n",
    "X_base_test = base_test.drop(['id','relevance'],axis=1).values\n",
    "y_base_test = base_test['relevance'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0f7e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_base = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=42)\n",
    "clf_base = BaggingRegressor(rf_base, n_estimators=45, max_samples=0.1, random_state=42)\n",
    "clf_base.fit(X_base_train, y_base_train)\n",
    "y_base_pred = clf_base.predict(X_base_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38a2dec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 0.4842\n",
      "Root Mean Squared Error (RMSE): 0.5245\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "rmse_base = np.sqrt(mean_squared_error(y_base_test, y_base_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_base:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab1aaf",
   "metadata": {},
   "source": [
    "# Improving the matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dcd4bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         attribute_name  count\n",
      "0        MFG Brand Name  86250\n",
      "1              Bullet02  86248\n",
      "2              Bullet03  86226\n",
      "3              Bullet04  86174\n",
      "4              Bullet01  85940\n",
      "5   Product Width (in.)  61137\n",
      "6              Bullet05  60529\n",
      "7  Product Height (in.)  54698\n",
      "8   Product Depth (in.)  53652\n",
      "9  Product Weight (lb.)  45175\n"
     ]
    }
   ],
   "source": [
    "attribute_counts = df_attr['name'].value_counts().reset_index()\n",
    "attribute_counts.columns = ['attribute_name', 'count']\n",
    "\n",
    "print(attribute_counts.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b1c0427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: mfg brand name\n",
      "Processing: material\n",
      "Processing: color/finish\n",
      "Processing: certifications and listings\n",
      "Processing: all_bullets\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "df_attr['name'] = df_attr['name'].fillna('').str.lower()\n",
    "df_attr['value'] = df_attr['value'].astype(str).str.lower()\n",
    "\n",
    "df_bullets = df_attr[df_attr['name'].str.startswith(\"bullet\")].copy()\n",
    "bullet_texts = df_bullets.groupby('product_uid')['value'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "bullet_texts = bullet_texts.rename(columns={'value': 'all_bullets'})\n",
    "\n",
    "df_complete = df_complete.merge(bullet_texts, on='product_uid', how='left')\n",
    "\n",
    "selected_attrs = ['mfg brand name', 'material', 'color/finish', 'certifications and listings']\n",
    "attributes = selected_attrs + ['all_bullets']\n",
    "\n",
    "for attr_name in attributes:\n",
    "    print(f\"Processing: {attr_name}\")\n",
    "\n",
    "    if attr_name == 'all_bullets':\n",
    "        attr_col = 'all_bullets'\n",
    "    else:\n",
    "        attr_subset = df_attr[df_attr['name'] == attr_name].drop_duplicates('product_uid')\n",
    "        attr_subset = attr_subset.rename(columns={'value': f'{attr_name}_value'})\n",
    "        df_complete = df_complete.merge(attr_subset[['product_uid', f'{attr_name}_value']], on='product_uid', how='left')\n",
    "        attr_col = f'{attr_name}_value'\n",
    "\n",
    "    def safe_similarity(row):\n",
    "        if pd.isna(row['search_term']) or pd.isna(row[attr_col]):\n",
    "            return 0.0\n",
    "        doc_query = nlp(row['search_term'])\n",
    "        doc_value = nlp(row[attr_col])\n",
    "        if doc_query.vector_norm == 0 or doc_value.vector_norm == 0:\n",
    "            return 0.0\n",
    "        return doc_query.similarity(doc_value)\n",
    "\n",
    "    df_complete[f'spacy_sim_{attr_name}'] = df_complete.apply(safe_similarity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e343391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_similarity(row):\n",
    "    doc1 = nlp(row['search_term'])\n",
    "    doc2 = nlp(row['product_title'])\n",
    "    if doc1.vector_norm == 0 or doc2.vector_norm == 0:\n",
    "        return 0.0\n",
    "    return doc1.similarity(doc2)\n",
    "\n",
    "df_complete['spacy_sim_title'] = df_complete.apply(spacy_similarity, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78051b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete['brand_match'] = df_complete.apply(\n",
    "    lambda row: int(str(row['search_term']).lower() in str(row.get('mfg brand name_value', '')).lower()), axis=1\n",
    ")\n",
    "\n",
    "def normalized_word_overlap(query, text):\n",
    "    q_words = set(query.split())\n",
    "    t_words = set(text.split())\n",
    "    if not q_words: return 0\n",
    "    return len(q_words & t_words) / len(q_words)\n",
    "\n",
    "df_complete['norm_overlap_title'] = df_complete.apply(\n",
    "    lambda row: normalized_word_overlap(row['search_term'], row['product_title']), axis=1\n",
    ")\n",
    "\n",
    "df_complete['length_diff'] = abs(\n",
    "    df_complete['search_term'].map(lambda x: len(x.split())) - \n",
    "    df_complete['product_title'].map(lambda x: len(x.split()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a8065b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf_cosine(df, col_text, new_feature_name):\n",
    "    corpus = pd.concat([df['search_term'], df[col_text]]).astype(str)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(corpus)\n",
    "\n",
    "    tfidf_query = vectorizer.transform(df['search_term'].astype(str))\n",
    "    tfidf_col = vectorizer.transform(df[col_text].astype(str))\n",
    "\n",
    "    df[new_feature_name] = [\n",
    "        cosine_similarity(tfidf_query[i], tfidf_col[i])[0][0]\n",
    "        for i in range(len(df))\n",
    "    ]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d47645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = df_complete.merge(df_pro_desc, on='product_uid', how='left')\n",
    "df_complete['product_description'] = df_complete['product_description'].fillna(\"\")\n",
    "df_complete['all_bullets'] = df_complete['all_bullets'].fillna(\"\")\n",
    "\n",
    "df_complete = compute_tfidf_cosine(df_complete, 'product_title', 'cosine_title')\n",
    "df_complete = compute_tfidf_cosine(df_complete, 'product_description', 'cosine_description')\n",
    "df_complete = compute_tfidf_cosine(df_complete, 'all_bullets', 'cosine_bullets')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19937192",
   "metadata": {},
   "source": [
    "# Adding numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55dd2e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: assembled height (in.)\n",
      "Processing: assembled width (in.)\n",
      "Processing: assembled depth (in.)\n",
      "Processing: product length (in.)\n",
      "Processing: product width (in.)\n",
      "Processing: product height (in.)\n",
      "Processing: product depth (in.)\n",
      "Processing: product weight (lb.)\n"
     ]
    }
   ],
   "source": [
    "num_attrs = [\n",
    "    'assembled height (in.)',\n",
    "    'assembled width (in.)',\n",
    "    'assembled depth (in.)',\n",
    "    'product length (in.)',\n",
    "    'product width (in.)',\n",
    "    'product height (in.)',\n",
    "    'product depth (in.)',\n",
    "    'product weight (lb.)'\n",
    "]\n",
    "\n",
    "for attr_name in num_attrs:\n",
    "    print(f\"Processing: {attr_name}\")\n",
    "    \n",
    "    attr_subset = df_attr[df_attr['name'] == attr_name].drop_duplicates('product_uid')\n",
    "    \n",
    "    if attr_subset.empty:\n",
    "        print(f\"⚠️ Attribute '{attr_name}' not found. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    col_name = f'{attr_name}_value'\n",
    "    if col_name in df_complete.columns:\n",
    "        df_complete.drop(columns=[col_name], inplace=True)\n",
    "\n",
    "    attr_subset = attr_subset.rename(columns={'value': col_name})\n",
    "    df_complete = df_complete.merge(attr_subset[['product_uid', col_name]], on='product_uid', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76cea873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numeric(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    val = str(val).lower().strip()\n",
    "    \n",
    "    if '-' in val:\n",
    "        parts = val.split('-')\n",
    "        try:\n",
    "            return float(parts[0]) + float(Fraction(parts[1]))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        return float(Fraction(val))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    match = re.search(r'(\\d+(\\.\\d+)?)', val)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f81c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in num_attrs:\n",
    "    col = f\"{attr}_value\"\n",
    "    num_col = f\"{attr}_num\"\n",
    "    df_complete[num_col] = df_complete[col].apply(extract_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58897159",
   "metadata": {},
   "source": [
    "# Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dec3bcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spacy_sim_mfg brand name', 'spacy_sim_material', 'spacy_sim_color/finish', 'spacy_sim_certifications and listings', 'spacy_sim_all_bullets', 'spacy_sim_title']\n",
      "RMSE with improved features: 0.4831\n",
      "Baseline RMSE: 0.4842\n"
     ]
    }
   ],
   "source": [
    "spacy_features = [col for col in df_complete.columns if col.startswith('spacy_sim_')]\n",
    "numeric_attr_features = [f\"{attr}_num\" for attr in num_attrs]\n",
    "\n",
    "improved = df_complete[\n",
    "    ['id', 'relevance', 'cosine_title', \"cosine_description\", \"cosine_bullets\", 'len_of_query',\n",
    "     'word_in_title', \"brand_match\", \"norm_overlap_title\", \"length_diff\"]\n",
    "    + spacy_features\n",
    "]\n",
    "\n",
    "improved_num = df_complete[\n",
    "    ['id', 'relevance', 'cosine_title', \"cosine_description\", \"cosine_bullets\", 'len_of_query',\n",
    "     'word_in_title', \"brand_match\", \"norm_overlap_title\", \"length_diff\"]\n",
    "    + spacy_features\n",
    "    + numeric_attr_features\n",
    "]\n",
    "\n",
    "train_idx = train.index\n",
    "test_idx = test.index\n",
    "\n",
    "X_improved_train = improved.loc[train_idx].drop(['id', 'relevance'], axis=1)\n",
    "X_improved_test = improved.loc[test_idx].drop(['id', 'relevance'], axis=1)\n",
    "y_improved_train = improved.loc[train_idx]['relevance'].values\n",
    "y_improved_test = improved.loc[test_idx]['relevance'].values\n",
    "\n",
    "X_improved_train_num = improved_num.loc[train_idx].drop(['id', 'relevance'], axis=1)\n",
    "X_improved_test_num = improved_num.loc[test_idx].drop(['id', 'relevance'], axis=1)\n",
    "y_improved_train_num = improved_num.loc[train_idx]['relevance'].values\n",
    "y_improved_test_num = improved_num.loc[test_idx]['relevance'].values\n",
    "\n",
    "rf_improved = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=42)\n",
    "clf_improved = BaggingRegressor(rf_improved, n_estimators=45, max_samples=0.1, random_state=42)\n",
    "clf_improved.fit(X_improved_train, y_improved_train)\n",
    "\n",
    "y_improved_pred = clf_improved.predict(X_improved_test)\n",
    "rmse_improved = np.sqrt(mean_squared_error(y_improved_test, y_improved_pred))\n",
    "\n",
    "print(f\"RMSE with improved features: {rmse_improved:.4f}\")\n",
    "print(f\"Baseline RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f76728c",
   "metadata": {},
   "source": [
    "# Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c506d787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest + Bagging    | RMSE: 0.4831 | Time: 6.94s\n",
      "Gradient Boosting         | RMSE: 0.4784 | Time: 12.40s\n",
      "HistGradientBoosting      | RMSE: 0.4788 | Time: 0.43s\n",
      "SVR                       | RMSE: 0.4931 | Time: 41.87s\n",
      "KNN                       | RMSE: 0.5211 | Time: 0.17s\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"RandomForest + Bagging\": clf_improved,\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, max_depth=4, random_state=42),\n",
    "    \"HistGradientBoosting\": HistGradientBoostingRegressor(max_iter=100, max_depth=4, random_state=42),    \n",
    "    \"SVR\": SVR(C=1.0, epsilon=0.2),\n",
    "    \"KNN\": KNeighborsRegressor(n_neighbors=5)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    start = time.time()\n",
    "    model.fit(X_improved_train, y_improved_train)\n",
    "    preds = model.predict(X_improved_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_improved_test, preds))\n",
    "    duration = time.time() - start\n",
    "    results[name] = (rmse, duration)\n",
    "\n",
    "for name, (rmse, time_taken) in results.items():\n",
    "    print(f\"{name:<25} | RMSE: {rmse:.4f} | Time: {time_taken:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c9eeb7",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization - Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba1ad2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best Gradient Boosting RMSE after tuning: 0.4764\n",
      "Best Parameters: {'subsample': 0.6, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 6, 'learning_rate': 0.05}\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=gbr,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=60, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_improved_train, y_improved_train)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "y_best_pred = best_model.predict(X_improved_test)\n",
    "rmse_best = np.sqrt(mean_squared_error(y_improved_test, y_best_pred))\n",
    "\n",
    "print(f\"Best Gradient Boosting RMSE after tuning: {rmse_best:.4f}\")\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50407da",
   "metadata": {},
   "source": [
    "# Model with numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cb7eec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best HistGradientBoosting RMSE after tuning: 0.4721\n",
      "Best Parameters: {'min_samples_leaf': 30, 'max_iter': 300, 'max_depth': None, 'max_bins': 255, 'learning_rate': 0.1, 'l2_regularization': 0.0, 'early_stopping': False}\n"
     ]
    }
   ],
   "source": [
    "# HistGradientBoosting because of NaN values\n",
    "\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'max_depth': [None, 3, 5, 7],\n",
    "    'min_samples_leaf': [10, 20, 30],\n",
    "    'l2_regularization': [0.0, 0.1, 0.5, 1.0],\n",
    "    'max_bins': [128, 255], \n",
    "    'early_stopping': [True, False]\n",
    "}\n",
    "\n",
    "hgb = HistGradientBoostingRegressor(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=hgb,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=60,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search.fit(X_improved_train_num, y_improved_train_num)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "y_best_pred = best_model.predict(X_improved_test_num)\n",
    "rmse_best = np.sqrt(mean_squared_error(y_improved_test_num, y_best_pred))\n",
    "\n",
    "print(f\"Best HistGradientBoosting RMSE after tuning: {rmse_best:.4f}\")\n",
    "print(\"Best Parameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44a6faf",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b951ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most important features (by permutation importance):\n",
      "                                  feature  importance_mean  importance_std\n",
      "6                      norm_overlap_title         0.020290        0.000694\n",
      "3                            len_of_query         0.019772        0.000665\n",
      "4                           word_in_title         0.018924        0.000882\n",
      "0                            cosine_title         0.016355        0.000760\n",
      "1                      cosine_description         0.009452        0.000594\n",
      "12                  spacy_sim_all_bullets         0.003396        0.000400\n",
      "21               product weight (lb.)_num         0.003365        0.000304\n",
      "13                        spacy_sim_title         0.003325        0.000282\n",
      "11  spacy_sim_certifications and listings         0.002601        0.000195\n",
      "18                product width (in.)_num         0.002108        0.000235\n",
      "7                             length_diff         0.002099        0.000198\n",
      "19               product height (in.)_num         0.001963        0.000252\n",
      "20                product depth (in.)_num         0.001673        0.000303\n",
      "8                spacy_sim_mfg brand name         0.001554        0.000226\n",
      "14             assembled height (in.)_num         0.001408        0.000108\n",
      "9                      spacy_sim_material         0.001377        0.000071\n",
      "16              assembled depth (in.)_num         0.001323        0.000141\n",
      "10                 spacy_sim_color/finish         0.001175        0.000231\n",
      "2                          cosine_bullets         0.000894        0.000274\n",
      "17               product length (in.)_num         0.000840        0.000136\n"
     ]
    }
   ],
   "source": [
    "# Run permutation importance on the test set\n",
    "result = permutation_importance(\n",
    "    best_model, X_improved_test_num, y_improved_test_num,\n",
    "    n_repeats=10, random_state=42, scoring='neg_root_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Convert to DataFrame\n",
    "importances_df = pd.DataFrame({\n",
    "    'feature': X_improved_test_num.columns,\n",
    "    'importance_mean': result.importances_mean,\n",
    "    'importance_std': result.importances_std\n",
    "}).sort_values(by='importance_mean', ascending=False)\n",
    "\n",
    "# Show top 5\n",
    "print(\"Top 5 most important features (by permutation importance):\")\n",
    "print(importances_df.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
